{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"D:\\work\\nlp\")\n",
    "from fennlp.datas import dataloader\n",
    "import tensorflow as tf\n",
    "from fennlp.datas.checkpoint import LoadCheckpoint\n",
    "from fennlp.datas.dataloader import TFWriter, TFLoader\n",
    "from fennlp.metrics import Metric\n",
    "from fennlp.metrics.crf import CrfLogLikelihood\n",
    "from fennlp.models import bert\n",
    "from fennlp.optimizers import optim\n",
    "from fennlp.tools import bert_init_weights_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_check = LoadCheckpoint(language='zh', is_download=False, file_path=r\"D:\\work\\nlp\\tests\\NER\\NER_ZH\\chinese_L-12_H-768_A-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param, vocab_file, model_path = load_check.load_bert_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.maxlen = 64\n",
    "param.batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_NER(tf.keras.Model):\n",
    "    def __init__(self, param, **kwargs):\n",
    "        super(BERT_NER, self).__init__(**kwargs)\n",
    "        self.batch_size = param.batch_size\n",
    "        self.maxlen = param.maxlen\n",
    "        self.label_size = param.label_size\n",
    "        self.bert = bert.BERT(param)\n",
    "        self.dense = tf.keras.layers.Dense(self.label_size, activation=\"relu\")\n",
    "        self.crf = CrfLogLikelihood()\n",
    "\n",
    "    def call(self, inputs, is_training=True):\n",
    "        # 数据切分\n",
    "        input_ids, token_type_ids, input_mask, Y = tf.split(inputs, 4, 0)\n",
    "        input_ids = tf.cast(tf.squeeze(input_ids, axis=0), tf.int64)\n",
    "        token_type_ids = tf.cast(tf.squeeze(token_type_ids, axis=0), tf.int64)\n",
    "        input_mask = tf.cast(tf.squeeze(input_mask, axis=0), tf.int64)\n",
    "        Y = tf.cast(tf.squeeze(Y, axis=0), tf.int64)\n",
    "        # 模型构建\n",
    "        bert = self.bert([input_ids, token_type_ids, input_mask], is_training)\n",
    "        sequence_output = bert.get_sequence_output()  # batch,sequence,768\n",
    "        predict = self.dense(sequence_output)\n",
    "        predict = tf.reshape(predict, [self.batch_size, self.maxlen, -1])\n",
    "        # 损失计算\n",
    "        log_likelihood, transition = self.crf(predict, Y, sequence_lengths=tf.reduce_sum(input_mask, 1))\n",
    "        loss = tf.math.reduce_mean(-log_likelihood)\n",
    "        predict, viterbi_score = self.crf.crf_decode(predict, transition,\n",
    "                                                     sequence_length=tf.reduce_sum(input_mask, 1))\n",
    "        return loss, predict\n",
    "\n",
    "    def predict(self, inputs, is_training=False):\n",
    "        loss, predict = self(inputs, is_training)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test\n",
      "Totally use 7 labels!\n",
      "\n",
      "ner_data\\test has been converted into ner_data\\test.tfrecords\n"
     ]
    }
   ],
   "source": [
    "writer = TFWriter(param.maxlen, vocab_file, modes=[\"test\"], input_dir=\"ner_data\", output_dir=\"ner_data\", check_exist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TFLoader(param.maxlen, param.batch_size, input_dir=\"ner_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = loader.load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, token_type_id, input_mask, Y = ds.__iter__().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(16, 64), dtype=int64, numpy=\n",
       " array([[ 101, 2769,  812, ...,    0,    0,    0],\n",
       "        [ 101,  711,  749, ...,    0,    0,    0],\n",
       "        [ 101, 1071,  704, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 7368, 7305, ...,    0,    0,    0],\n",
       "        [ 101,  788,  788, ...,    0,    0,    0],\n",
       "        [ 101, 1591, 6814, ...,    0,    0,    0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(16, 64), dtype=int64, numpy=\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(16, 64), dtype=int64, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(16, 64), dtype=int64, numpy=\n",
       " array([[6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        ...,\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6]], dtype=int64)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X, token_type_id, input_mask, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(16, 64), dtype=int64, numpy=\n",
       "  array([[ 101, 2769,  812, ...,    0,    0,    0],\n",
       "         [ 101,  711,  749, ...,    0,    0,    0],\n",
       "         [ 101, 1071,  704, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 7368, 7305, ...,    0,    0,    0],\n",
       "         [ 101,  788,  788, ...,    0,    0,    0],\n",
       "         [ 101, 1591, 6814, ...,    0,    0,    0]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(16, 64), dtype=int64, numpy=\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(16, 64), dtype=int64, numpy=\n",
       "  array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(16, 64), dtype=int64, numpy=\n",
       "  array([[6, 6, 6, ..., 6, 6, 6],\n",
       "         [6, 6, 6, ..., 6, 6, 6],\n",
       "         [6, 6, 6, ..., 6, 6, 6],\n",
       "         ...,\n",
       "         [6, 6, 6, ..., 6, 6, 6],\n",
       "         [6, 6, 6, ..., 6, 6, 6],\n",
       "         [6, 6, 6, ..., 6, 6, 6]], dtype=int64)>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
